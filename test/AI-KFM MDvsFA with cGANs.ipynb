{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed705150",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3253cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from aikfm.dataset import AikfmDataset\n",
    "from aikfm.models import CAN8, UCAN64, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35c859dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch_num = 30\n",
    "mini_batch_size = 2\n",
    "lambda1 = 100\n",
    "lambda2 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be26095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AikfmDataset(\"~/DKLabs/AI-KFM/AI-KFM/data\")\n",
    "dataloader = DataLoader(dataset, batch_size=mini_batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "747335ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discriminator(\n",
       "  (leakyrelu1): LeakyReLU(negative_slope=0.2)\n",
       "  (leakyrelu2): LeakyReLU(negative_slope=0.2)\n",
       "  (leakyrelu3): LeakyReLU(negative_slope=0.2)\n",
       "  (leakyrelu4): LeakyReLU(negative_slope=0.2)\n",
       "  (Tanh1): Tanh()\n",
       "  (Tanh2): Tanh()\n",
       "  (Tanh3): Tanh()\n",
       "  (Softmax): Softmax(dim=None)\n",
       "  (d_conv1): Conv2d(4, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (d_conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (d_conv3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (d_conv4): Conv2d(24, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (d_bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (d_bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (d_bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (d_bn4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (d_bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (d_bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (d_bn7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (d_bn8): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=2500, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generater 1\n",
    "g1 = CAN8()\n",
    "g1.to(device)\n",
    "\n",
    "# Generator 2\n",
    "g2 = UCAN64()\n",
    "g2.to(device)\n",
    "\n",
    "# Discriminator\n",
    "dis = discriminator()\n",
    "dis.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5100e837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizers\n",
    "optim_g1 = optim.AdamW(g1.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "optim_g2 = optim.AdamW(g2.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "optim_dis = optim.AdamW(dis.parameters(), lr=1e-5, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c1da4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss1 = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8eb6444",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, masks = iter(dataloader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f7def35",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, masks = imgs.to(device), masks.to(device) # Move data to compute Device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4704dd",
   "metadata": {},
   "source": [
    "### Discriminator training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab857b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Train the discriminator first\n",
    "dis.train()\n",
    "g1.eval()\n",
    "g2.eval()\n",
    "optim_g1.zero_grad()\n",
    "optim_g2.zero_grad()\n",
    "optim_dis.zero_grad()\n",
    "\n",
    "# Get generator outputs\n",
    "g1_out = g1(imgs) # [B, 1, 1200, 1600]\n",
    "g1_out = torch.clamp(g1_out, 0.0, 1.0)\n",
    "\n",
    "g2_out = g2(imgs) # [B, 1, 1200, 1600]\n",
    "g2_out = torch.clamp(g2_out, 0.0, 1.0)\n",
    "\n",
    "pos1 = torch.cat([imgs, 2 * masks - 1], dim = 1) # [B, 4, H, W]\n",
    "neg1 = torch.cat([imgs, 2 * g1_out - 1], dim = 1) # [B, 4, H, W]\n",
    "neg2 = torch.cat([imgs, 2 * g2_out - 1], dim = 1) # [B, 4, H, W]\n",
    "\n",
    "dis_input = torch.cat([pos1, neg1, neg2], dim=0) # # [3*B, 4, H, W]\n",
    "\n",
    "# Get discriminator output\n",
    "logits_real, logits_fake1, logits_fake2, Lgc = dis(dis_input)\n",
    "\n",
    "const1 = torch.ones(imgs.size(0), 1, device=device, dtype=torch.float32)\n",
    "const0 = torch.zeros(imgs.size(0), 1, device=device, dtype=torch.float32)\n",
    "\n",
    "gen_gt = torch.cat([const1, const0, const0], dim=1)\n",
    "gen_gt1 = torch.cat([const0, const1, const0], dim=1)\n",
    "gen_gt2 = torch.cat([const0, const0, const1], dim=1)\n",
    "\n",
    "ES0 = torch.mean(loss1(logits_real, gen_gt))\n",
    "ES1 = torch.mean(loss1(logits_fake1, gen_gt1))\n",
    "ES2 = torch.mean(loss1(logits_fake2, gen_gt2))\n",
    "\n",
    "dis_loss = ES0 + ES1 + ES2 # Discriminator loss\n",
    "print(f'Discriminator loss : {dis_loss}')\n",
    "\n",
    "dis_loss.backward() # Compute gradients\n",
    "optim_dis.step() # Apply gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167a04a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
