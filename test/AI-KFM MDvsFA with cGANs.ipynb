{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d6ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ff63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from aikfm.dataset import AikfmDataset\n",
    "from aikfm.models import CAN8, UCAN64, discriminator\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffd2d959",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch_num = 30\n",
    "mini_batch_size = 2\n",
    "lambda1 = 100\n",
    "lambda2 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff910e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AikfmDataset(\"~/DKLabs/AI-KFM/AI-KFM/data\")\n",
    "dataloader = DataLoader(dataset, batch_size=mini_batch_size, shuffle=True)\n",
    "\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b422f575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAN8(\n",
       "  (leakyrelu1): LeakyReLU(negative_slope=0.2)\n",
       "  (leakyrelu2): LeakyReLU(negative_slope=0.2)\n",
       "  (leakyrelu3): LeakyReLU(negative_slope=0.2)\n",
       "  (leakyrelu4): LeakyReLU(negative_slope=0.2)\n",
       "  (leakyrelu5): LeakyReLU(negative_slope=0.2)\n",
       "  (leakyrelu6): LeakyReLU(negative_slope=0.2)\n",
       "  (leakyrelu7): LeakyReLU(negative_slope=0.2)\n",
       "  (leakyrelu8): LeakyReLU(negative_slope=0.2)\n",
       "  (g1_conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (g1_conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (g1_conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (g1_conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "  (g1_conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
       "  (g1_conv6): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "  (g1_conv7): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (g1_conv8): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (g1_conv9): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (g1_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (g1_bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (g1_bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (g1_bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (g1_bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (g1_bn6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (g1_bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (g1_bn8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generater 1\n",
    "g1 = CAN8()\n",
    "g1.to(device)\n",
    "\n",
    "# # Generator 2\n",
    "# g2 = UCAN64()\n",
    "# g2.to(device)\n",
    "\n",
    "# # Discriminator\n",
    "# dis = discriminator()\n",
    "# dis.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1e39457",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 470.00 MiB (GPU 0; 3.82 GiB total capacity; 1.39 GiB already allocated; 109.25 MiB free; 1.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/clort/lib/python3.8/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m~/.venv/clort/lib/python3.8/site-packages/torch/nn/modules/module.py:1111\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/DKLabs/AI-KFM/AI-KFM/aikfm/models/can8.py:57\u001b[0m, in \u001b[0;36mCAN8.forward\u001b[0;34m(self, input_images)\u001b[0m\n\u001b[1;32m     54\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg1_bn4(net)\n\u001b[1;32m     55\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleakyrelu4(net)\n\u001b[0;32m---> 57\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg1_conv5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg1_bn5(net)\n\u001b[1;32m     59\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleakyrelu5(net)\n",
      "File \u001b[0;32m~/.venv/clort/lib/python3.8/site-packages/torch/nn/modules/module.py:1129\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1129\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n",
      "File \u001b[0;32m~/.venv/clort/lib/python3.8/site-packages/torch/nn/modules/conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/clort/lib/python3.8/site-packages/torch/nn/modules/conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    441\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    442\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 470.00 MiB (GPU 0; 3.82 GiB total capacity; 1.39 GiB already allocated; 109.25 MiB free; 1.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "summary(g1, (3, 200, 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed65ede9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 1            |        cudaMalloc retries: 2         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    1423 MB |    1423 MB |    1601 MB |  182553 KB |\n",
      "|       from large pool |    1422 MB |    1422 MB |    1599 MB |  181441 KB |\n",
      "|       from small pool |       0 MB |       1 MB |       1 MB |    1112 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    1423 MB |    1423 MB |    1601 MB |  182553 KB |\n",
      "|       from large pool |    1422 MB |    1422 MB |    1599 MB |  181441 KB |\n",
      "|       from small pool |       0 MB |       1 MB |       1 MB |    1112 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    1444 MB |    1444 MB |    1624 MB |  184320 KB |\n",
      "|       from large pool |    1442 MB |    1442 MB |    1622 MB |  184320 KB |\n",
      "|       from small pool |       2 MB |       2 MB |       2 MB |       0 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   21058 KB |   21058 KB |   38992 KB |   17934 KB |\n",
      "|       from large pool |   19779 KB |   19779 KB |   35839 KB |   16059 KB |\n",
      "|       from small pool |    1278 KB |    2041 KB |    3153 KB |    1875 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |      79    |      79    |      83    |       4    |\n",
      "|       from large pool |      17    |      17    |      19    |       2    |\n",
      "|       from small pool |      62    |      62    |      64    |       2    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |      79    |      79    |      83    |       4    |\n",
      "|       from large pool |      17    |      17    |      19    |       2    |\n",
      "|       from small pool |      62    |      62    |      64    |       2    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      14    |      15    |      16    |       2    |\n",
      "|       from large pool |      13    |      14    |      15    |       2    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      11    |      11    |      13    |       2    |\n",
      "|       from large pool |      10    |      10    |      12    |       2    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b9c32a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizers\n",
    "optim_g1 = optim.AdamW(g1.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "optim_g2 = optim.AdamW(g2.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "optim_dis = optim.AdamW(dis.parameters(), lr=1e-5, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe3cb371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss1 = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3de8ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, masks = iter(dataloader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80119b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, masks = imgs.to(device), masks.to(device) # Move data to compute Device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69739e11",
   "metadata": {},
   "source": [
    "### Discriminator training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187af153",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Train the discriminator first\n",
    "dis.train()\n",
    "g1.eval()\n",
    "g2.eval()\n",
    "optim_g1.zero_grad()\n",
    "optim_g2.zero_grad()\n",
    "optim_dis.zero_grad()\n",
    "\n",
    "# Get generator outputs\n",
    "g1_out = g1(imgs) # [B, 1, 1200, 1600]\n",
    "g1_out = torch.clamp(g1_out, 0.0, 1.0)\n",
    "\n",
    "g2_out = g2(imgs) # [B, 1, 1200, 1600]\n",
    "g2_out = torch.clamp(g2_out, 0.0, 1.0)\n",
    "\n",
    "pos1 = torch.cat([imgs, 2 * masks - 1], dim = 1) # [B, 4, H, W]\n",
    "neg1 = torch.cat([imgs, 2 * g1_out - 1], dim = 1) # [B, 4, H, W]\n",
    "neg2 = torch.cat([imgs, 2 * g2_out - 1], dim = 1) # [B, 4, H, W]\n",
    "\n",
    "dis_input = torch.cat([pos1, neg1, neg2], dim=0) # # [3*B, 4, H, W]\n",
    "\n",
    "# Get discriminator output\n",
    "logits_real, logits_fake1, logits_fake2, Lgc = dis(dis_input)\n",
    "\n",
    "const1 = torch.ones(imgs.size(0), 1, device=device, dtype=torch.float32)\n",
    "const0 = torch.zeros(imgs.size(0), 1, device=device, dtype=torch.float32)\n",
    "\n",
    "gen_gt = torch.cat([const1, const0, const0], dim=1)\n",
    "gen_gt1 = torch.cat([const0, const1, const0], dim=1)\n",
    "gen_gt2 = torch.cat([const0, const0, const1], dim=1)\n",
    "\n",
    "ES0 = torch.mean(loss1(logits_real, gen_gt))\n",
    "ES1 = torch.mean(loss1(logits_fake1, gen_gt1))\n",
    "ES2 = torch.mean(loss1(logits_fake2, gen_gt2))\n",
    "\n",
    "dis_loss = ES0 + ES1 + ES2 # Discriminator loss\n",
    "print(f'Discriminator loss : {dis_loss}')\n",
    "\n",
    "dis_loss.backward() # Compute gradients\n",
    "optim_dis.step() # Apply gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ddd05f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
